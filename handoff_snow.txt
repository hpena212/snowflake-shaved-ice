{ type: uploaded file fileName: Project_Handoff_Status.md fullContent:

üçß Shaved Ice Project: Handoff & Status Report
Current Date: Jan 12, 2026 User: Hector Pe√±a Role: Senior Analytics Engineer (Student) Goal: ICPE 2026 Data Challenge Submission (4-page paper) Deadline: Jan 28, 2026

üö¶ Project Status: "The Bridge is Built"
Architecture: Hybrid Workflow (dbt/DuckDB for Engineering ‚û° Python/Pandas for Analysis).

Progress:

‚úÖ Environment Configured (venv, git).

‚úÖ dbt Project Initialized & Models Running.

‚úÖ Python connected to DuckDB (src/duckdb_loader.py).

‚úÖ Major Milestone: "Inventory Audit" complete. We have successfully visualized Demand vs. Safety Stock.

Key Insight: The dataset already contains pre-calculated safety stocks (safety_stock_95pct), but they represent the buffer margin only. To see Total Capacity, we must calculate: Total Capacity = Rolling Average Demand + Safety Stock.

üí° 5 Strategic Directions (Next Steps)
Here are 5 potential paths to take the analysis next. Each moves the project from "Descriptive" (what happened) to "Diagnostic" or "Prescriptive" (what should we do), which is better for the research paper.

Path 1: The "Inefficiency Auditor" (Regional Comparison)
Concept: Just like comparing two retail store locations. One store runs lean and efficient; the other hoards inventory "just in case."

Hypothesis: Some cloud regions are "hoarding" VMs (keeping safety stock too high relative to volatility), wasting money.

Output: A scatter plot of Volatility vs. Utilization % by region.

Path 2: The "Stockout" Stress Test
Concept: When did the store actually run out of product?

Hypothesis: The provided safety_stock_95pct failed during specific high-stress events (e.g., Black Friday, End of Quarter).

Output: A "Disaster Log" table identifying every date where Actual Demand > Total Capacity.

Path 3: The "Seasonal Rhythm" (Time-of-Day/Week Analysis)
Concept: Stores have rush hours. Does the cloud?

Hypothesis: Demand is not random; it has a "heartbeat." We can reduce safety stock during known "quiet hours" (nights/weekends) to save money.

Output: Heatmaps showing demand intensity by Day of Week vs. Hour of Day.

Path 4: The "Cost of Quality" (Service Level Trade-off)
Concept: Is 99% uptime worth the cost?

Hypothesis: Moving from 95% reliability to 99% reliability doubles the inventory cost but only saves 4 outage hours a year.

Output: A "Cost vs. Reliability" curve (The Efficient Frontier).

Path 5: The "Forecasting Upgrade" (Python Custom Model)
Concept: The current model uses a simple rolling average. Can we beat it?

Hypothesis: A Holt-Winters Exponential Smoothing model (in Python) will predict spikes better than the simple moving average provided in the dataset.

Output: A "Model Battle" chart: Actual vs. Rolling Avg vs. Holt-Winters.

üõ†Ô∏è SQL Queries (New dbt Models)
To explore Paths 1, 2, and 3, create these new SQL models in your models/marts/ folder. These aggregate the data in new ways to reveal patterns.

1. For Path 1 (Efficiency): models/marts/mart_regional_efficiency.sql
Calculates how "tight" each region runs its inventory.

SQL

WITH daily_stats AS (
    SELECT 
        region,
        instance_type,
        -- Calculate how much "inventory" was actually used
        SUM(demand) as total_demand_volume,
        -- Calculate how much capacity was provisioned (Avg + Buffer)
        SUM(demand_rolling_7d_avg + safety_stock_95pct) as total_capacity_provisioned,
        -- Volatility Metric
        STDDEV(demand) as demand_volatility
    FROM {{ ref('mart_forecast_input') }} -- References your main table
    GROUP BY 1, 2
)

SELECT 
    *,
    -- Utilization Rate: Higher is more efficient (less waste)
    (total_demand_volume / NULLIF(total_capacity_provisioned, 0)) * 100 as utilization_pct,
    -- Hoarding Index: High volatility usually justifies low utilization, but low vol + low util = hoarding
    demand_volatility / NULLIF(total_demand_volume, 0) as volatility_ratio
FROM daily_stats
ORDER BY utilization_pct ASC
2. For Path 2 (Stockouts): models/marts/mart_stockout_events.sql
Finds the specific days the "system crashed" (Stockouts).

SQL

SELECT 
    date,
    region,
    instance_type,
    demand as actual_demand,
    (demand_rolling_7d_avg + safety_stock_95pct) as total_capacity_95,
    -- Calculate the deficit
    demand - (demand_rolling_7d_avg + safety_stock_95pct) as stockout_size,
    -- Flag severity
    CASE 
        WHEN demand > (demand_rolling_7d_avg + safety_stock_99pct) THEN 'Critical Failure (99% Breached)'
        WHEN demand > (demand_rolling_7d_avg + safety_stock_95pct) THEN 'Warning (95% Breached)'
        ELSE 'Safe'
    END as status
FROM {{ ref('mart_forecast_input') }}
WHERE demand > (demand_rolling_7d_avg + safety_stock_95pct)
ORDER BY stockout_size DESC
3. For Path 3 (Seasonality): models/marts/mart_seasonal_patterns.sql
Aggregates data by Day of Week to find the "Weekend Effect."

SQL

SELECT 
    region,
    day_of_week, -- 0=Monday, 6=Sunday (depending on DB settings)
    AVG(demand) as avg_demand,
    MAX(demand) as peak_demand,
    MIN(demand) as floor_demand,
    -- The "Weekend Drop": compare avg demand to global avg
    AVG(demand) - (SELECT AVG(demand) FROM {{ ref('mart_forecast_input') }}) as diff_from_global_avg
FROM {{ ref('mart_forecast_input') }}
GROUP BY 1, 2
ORDER BY region, day_of_week
üìù Suggested Next Prompt for AI
"I have my dbt environment set up and the 'Inventory Audit' complete. I want to pursue Path 2: The Stockout Stress Test. Help me create the mart_stockout_events SQL model, run it, and then use Python to visualize the 'Worst Day in History' for this cloud region." }